# Causal Analysis and Interactive Reasoning over Conversational Data

## ğŸ“Œ Project Overview
This project implements an end-to-end system for **causal analysis and interactive reasoning** over multi-turn conversational transcripts. The system goes beyond simple outcome prediction by identifying **why an outcome occurred** using faithful, evidence-backed dialogue turns. It also supports multi-turn analytical queries.

---

## ğŸ¯ Objectives
- Predict outcome events such as refunds, escalations, delays, and resolutions  
- Identify causal dialogue turns responsible for each outcome  
- Provide interpretable and traceable explanations  
- Support interactive follow-up queries with contextual consistency  
- Avoid hallucination through model-driven causal attribution  

---

## ğŸ—ï¸ System Architecture

### ğŸ”¹ Stage 1 â€“ Outcome Prediction
- Transformer-based (BERT) conversation classifier  
- Predicts final outcome of a conversation  

### ğŸ”¹ Stage 2 â€“ Turn-Level Causal Attribution
- Leave-One-Out (LOO) confidence drop analysis  
- Assigns importance scores to dialogue turns  
- Extracts top-ranked turns as causal evidence  

### ğŸ”¹ Stage 3 â€“ Interactive Query Handling
- Handles natural-language analytical queries  
- Maintains multi-turn query context  
- Returns structured explanations with evidence  

---

## ğŸ“‚ Project Structure
â”œâ”€â”€ structured_dataset.csv
â”œâ”€â”€ queries.csv
â”œâ”€â”€ results/
â”œâ”€â”€ logs/
â”œâ”€â”€ notebook.ipynb
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md


---

## ğŸ“Š Dataset Description

The dataset consists of structured conversational transcripts where each conversation contains multiple dialogue turns, and the outcome label is defined at the conversation level.

### Dataset Columns
- **transcript_id** â†’ Unique identifier for each conversation  
- **turn_id** â†’ Sequential order of dialogue turns  
- **speaker** â†’ Speaker role (Agent or Customer)  
- **text** â†’ Utterance content  
- **intent** â†’ High-level issue category (e.g., delivery, appointment)  
- **domain** â†’ Business domain  
- **reason** â†’ Outcome explanation label  

### Preprocessing Notes
- Only spoken dialogue turns (Agent & Customer) are used  
- System summaries and metadata entries are excluded to prevent label leakage  

---

## âš™ï¸ Setup & Installation

### Environment Requirements
- Python 3.9 or higher  

### Create Virtual Environment

python -m venv venv
Execution Guide
###âœ… Stage 1 â€“ Outcome Prediction Training
Open the provided notebook
Run Stage 1 cells
Train BERT-based classifier
Best checkpoint is saved automatically in results/

###âœ… Stage 2 â€“ Turn-Level Evidence Extraction
Load trained model
Apply Leave-One-Out attribution
Rank dialogue turns by causal importance
Example Output
Importance Score: 0.79
Turn: Customer: The tracking shows delivered, but nothing arrived.

###âœ… Stage 3 â€“ Query-Driven Interaction
Example Queries
Why do delivery-related conversations result in refunds?
Which dialogue turn contributed most to the outcome?
System Behavior
Filters relevant conversations
Extracts causal evidence
Maintains context for follow-up queries

###ğŸ“ Query Dataset (queries.csv)
Contains:
Query ID
Query text
Query category
System output
Remarks explaining causal reasoning

###ğŸ“ˆ Evaluation Metrics
Accuracy
Macro F1-score
Evidence faithfulness
Turn-level ID recall
##Stage 1 Results
Accuracy: 0.88
Macro F1-score: 0.80

###ğŸ” Faithfulness Guarantee
Model-driven Leave-One-Out causal attribution
Confidence-drop based importance scoring
Exact dialogue turns extracted as evidence
No generative hallucination used

###ğŸ” Reproducibility
Use provided dataset
Run notebook sequentially
Maintain same random seed
Use provided requirements.txt

###ğŸ”® Future Work
Hierarchical turn-level Transformer models
Temporal modeling using timestamps
Visualization dashboards for causal evidence
Cross-conversation causal pattern mining

###ğŸ“Œ Conclusion
This project demonstrates how conversational machine learning systems can move beyond prediction toward causal, interpretable, and interactive reasoning. The approach is scalable, faithful, and aligned with real-world conversational analytics requirements.

###ğŸ“¬ Contact
Refer to the technical report or notebook documentation for additional details.
